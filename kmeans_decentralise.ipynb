{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "black-horse",
   "metadata": {},
   "source": [
    "L'objectif de ce mini-projet est de simuler l'execution du K-means en mode distribue pour l'adapter aux contraintes du Big Data, en particulier la décentralisation des données.\n",
    "Il est ainsi interdit de rapatrier toutes les données en memoire (chose impossible en Big Data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211dd080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des packages pour le tp\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1488550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install glob2\n",
    "# !pip install cassandra-driver==3.24.0\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-section",
   "metadata": {},
   "source": [
    "# K-means simple :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a7d1c",
   "metadata": {},
   "source": [
    "C'est ce kmeans qui sera adapté par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05e07679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_(feats, num_clus):\n",
    "    # Initialiser le nombre maximal d'itérations et le changement maximal de centroïdes\n",
    "    max_iter = 10000\n",
    "    # Initialiser un objet NearestNeighbors pour trouver les plus proches voisins en utilisant l'algorithme 'ball_tree'\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "    # Initialiser les variables pour suivre l'itération courante et le changement de centroïdes\n",
    "    iter_ = 0\n",
    "    # Sélectionner aléatoirement les centroïdes initiaux à partir des points de données en entrée (feats)\n",
    "    centroides = feats[np.random.choice(feats.shape[0], num_clus, replace=False), :]\n",
    "    # Répéter jusqu'à ce que le nombre maximal d'itérations soit atteint\n",
    "    while(iter_ < max_iter):\n",
    "        # Mettre à jour l'objet NearestNeighbors avec les centroïdes courants\n",
    "        nbrs.fit(centroides)        \n",
    "        # Incrémenter le compteur d'itérations\n",
    "        iter_ += 1        \n",
    "        # Trouver les plus proches voisins de chaque centroïde et calculer les distances\n",
    "        distances, indices = nbrs.kneighbors(feats)\n",
    "        # Créer une copie des centroïdes actuels pour effectuer une comparaison ultérieure\n",
    "        centroides_prev = copy.deepcopy(centroides)\n",
    "        # Mettre à jour la position de chaque centroïde en calculant la moyenne de ses plus proches voisins\n",
    "        for i in range(centroides.shape[0]):\n",
    "            centroides[i, :] = feats[np.where(indices[:, 0] == i)[0], :].mean(axis=0)\n",
    "\n",
    "    # Retourner les indices des plus proches voisins de chaque centroïde et la distance moyenne à ces voisins\n",
    "    return indices[:, 0], distances.mean()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "mighty-programming",
   "metadata": {},
   "source": [
    "On commence par remplir 3 table sur Cassandra avec 100000 element chacune\n",
    "Chaque table contient 4 colonnes\n",
    "\n",
    "Les tables suivent la structure suivante :\n",
    "ID_pref (Partition key),Id_company, age, weight, shoulder circumference\n",
    "\n",
    "Id_company est unique pour chaque ligne\n",
    "La colonne ID_pref est assigné une des trois valeurs (0,1,2). 40% des lignes ont une valeure de 0. Les valeurs de 1 et 2 representent 30% chacune. \n",
    "\n",
    "Pour la première table\n",
    "A la colonne age, est assignée une valeur suivant une loi normale entre 18 et 99 avec une moyenne=30 et un écart type = 10  (on utilise scipy.stats).\n",
    "La colonne weight et shoulder circumference sont aleatoires (on utilise numpy.random). \n",
    "50<weight<99 et 30<shoulder circumference <60\n",
    "\n",
    "Pour la seconde table \n",
    "A la colonne age, est assignée une valeur suivant une loi normale entre 18 et 99 avec moyenne=30 et écart type = 15  (utilisez scipy.stats).\n",
    "La colonne weight est assigné une valeur suivant une loi normale entre 50 et 99 avec moyenne=70 et écart type = 10  (utilisez scipy.stats).\n",
    "30<shoulder circumference (aleatoire) <60\n",
    "\n",
    "la troisième table utilise le même modèle que la tablea précedente pour genèrer la colonne age\n",
    "Le poids et shoulder circumference dependent de l'age :\n",
    "Poids = 50 + sqrt(age)\n",
    "shoulder circumference = 10 + 2*log(age)\n",
    "ID_pref = les identifiants des personnes dépendent de leur age comme suit: \n",
    "- 0 au premiers 40% (les plus jeunes)\n",
    "- 1 au second 30% \n",
    "- 2 au dernier 30% (les plus âgées) \n",
    "\n",
    "\n",
    "NB\n",
    "On commence par faire l'exercice sur un dictionnaire (cassandra_dict={}, avec cassandra_dict[table1],cassandra_dict[table2],cassandra_dict[table3] representant les tables). On modifie ensuite le code pour s'executer sur cassandra."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1e3aa84",
   "metadata": {},
   "source": [
    "## Travail préliminaire : création d'un cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30cc76a9",
   "metadata": {},
   "source": [
    " Afin de travailler avec cassandra sur ma machine, j'ai crée un cluster à 3 noeuds avec docker-compose (voir fichier docker-compose.yaml). J'utilise ce uster dans la suite du projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf4c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "\n",
    "cluster_addresses = ['172.31.160.1']\n",
    "auth_provider = PlainTextAuthProvider(username='cassandra', password='cassandra')\n",
    "cluster=Cluster(cluster_addresses, auth_provider=auth_provider,  connect_timeout=10)#127.0.0.1\n",
    "session=cluster.connect()\n",
    "keyspace = \"ai\"\n",
    "timeout = 20\n",
    "replication = \"{'class': 'SimpleStrategy', 'replication_factor': 1}\"\n",
    "session.execute(f\"CREATE KEYSPACE IF NOT EXISTS {keyspace} WITH replication = {replication}\", timeout=timeout)\n",
    "session.set_keyspace(keyspace)\n",
    "#session.execute(\"drop table python_test\")\n",
    "session.execute(\"create table if not exists python_test(id uuid primary key, name text, lastname text)\", timeout=timeout)\n",
    "for i in range(10):\n",
    "    session.execute(\"insert into python_test(id,name,lastname) values(uuid(), 'prenom_\"+str(i)+\"','nom') if not exists\")\n",
    "res=session.execute(\"select * from python_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf08ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ferme la connexion au cluster\n",
    "cluster.shutdown()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5302056e",
   "metadata": {},
   "source": [
    "### Création des dictionnaires pour l'exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "773a7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser un dictionnaire vide pour stocker les tables\n",
    "cassandra_dict = {}\n",
    "\n",
    "# Initialiser les tables avec des listes vides\n",
    "cassandra_dict[\"table1\"] = []\n",
    "cassandra_dict[\"table2\"] = []\n",
    "cassandra_dict[\"table3\"] = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43ae9de9",
   "metadata": {},
   "source": [
    "### Définition de fonction qui servira aussi dans la suite du projet\n",
    "\n",
    "La fonction `genere_nombre` utilise une distribution normale tronquée pour générer des nombres aléatoires dans un intervalle donné. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c59b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour générer un nombre aléatoire basé sur une distribution normale tronquée, dans un intervalle donné\n",
    "def genere_nombre(mu, sigma, min_intervale, max_intervale, nombre_donnees=1):\n",
    "    # Crée une distribution normale tronquée avec les paramètres mu (moyenne), sigma (écart-type), \n",
    "    # et les limites de l'intervalle (min_intervale et max_intervale)\n",
    "    norm_dist = scipy.stats.truncnorm((min_intervale - mu) / sigma, (max_intervale - mu) / sigma, loc=mu, scale=sigma)\n",
    "    \n",
    "    # Génère un échantillon aléatoire à partir de la distribution normale tronquée créée précédemment\n",
    "    return norm_dist.rvs(size=nombre_donnees).reshape(nombre_donnees, 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfe62a26",
   "metadata": {},
   "source": [
    "### Génération des données\n",
    "Je génére les données en m'assurant que l'id_company est unique sur les 3 tables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5473291",
   "metadata": {},
   "source": [
    "#### Données de la table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e60e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit une variable 'N' égale à 100 000\n",
    "N = 100_000\n",
    "\n",
    "# On génère un vecteur des 'id_pref' de taille N en choisissant aléatoirement \n",
    "# parmi 0, 1 et 2 selon les probabilités 0.4, 0.3 et 0.3\n",
    "id_pref = np.random.choice([0, 1, 2], p=[0.4, 0.3, 0.3], size=N).reshape(N,1).astype('int')\n",
    "\n",
    "# On crée un vecteur des 'id_company_1' avec des valeurs allant de 1 à N inclus\n",
    "id_company_1 = np.array(range(1,N+1)).reshape(N,1).astype('int')\n",
    "\n",
    "# On génère un vecteur des 'ages_t1' de taille N avec des valeurs entières générées par la fonction 'genere_nombre'\n",
    "ages_t1 = genere_nombre(30,10,18,99,N).round(0).astype('int')\n",
    "\n",
    "# On génère un vecteur des 'weights_t1' de taille N avec des valeurs uniformément réparties entre 50 et 99, \n",
    "# arrondies à 2 décimales\n",
    "weights_t1 = np.random.uniform(50, 99, size=N).round(2).reshape(N, 1)\n",
    "\n",
    "# On génère un vecteur des 'shoulder_circumference_t1' de taille N avec des valeurs uniformément réparties \n",
    "# entre 30 et 60 \n",
    "shoulder_circumference_t1 = np.random.uniform(30, 60, size=N).round(2).reshape(N,1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cdc31dc",
   "metadata": {},
   "source": [
    "Je convertis les données générées en liste pour l'implémentation dans cassandra et les ajoute au disctionnaire `cassandra_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85590307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassandra_dict['table1'] = [x.tolist() for x in (id_pref,id_company_1,ages_t1,weights_t1,shoulder_circumference_t1)]\n",
    "cassandra_dict['table1'] = [[x[i][0]for x in cassandra_dict['table1']] for i in range(len(cassandra_dict['table1'][0])) ]\n",
    "len(cassandra_dict['table1'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "706babfd",
   "metadata": {},
   "source": [
    "Je m'assure que les données sont correctes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aabed3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 38, 56.66, 43.31],\n",
       " [1, 2, 53, 53.32, 30.7],\n",
       " [0, 3, 20, 68.95, 47.78],\n",
       " [2, 4, 18, 69.29, 46.69],\n",
       " [2, 5, 32, 61.82, 33.26],\n",
       " [2, 6, 29, 53.73, 56.74],\n",
       " [0, 7, 18, 71.09, 46.04],\n",
       " [1, 8, 34, 89.42, 55.69],\n",
       " [2, 9, 48, 66.28, 56.97],\n",
       " [2, 10, 28, 59.65, 51.4]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassandra_dict['table1'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac188559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "008d4ba1",
   "metadata": {},
   "source": [
    "#### Données de la table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75d33df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit une variable 'N' égale à 100 000\n",
    "N = 100_000\n",
    "\n",
    "# On génère un vecteur des 'id_pref' de taille N en choisissant aléatoirement \n",
    "# parmi 0, 1 et 2 selon les probabilités 0.4, 0.3 et 0.3\n",
    "id_pref = np.random.choice([0, 1, 2], p=[0.4, 0.3, 0.3], size=N).reshape(N,1).astype('int')\n",
    "\n",
    "# On crée un vecteur des 'id_company_2' avec des valeurs allant de N+1 à 2*N inclus\n",
    "id_company_2 = np.array(range(N+1,2*N+1)).reshape(N,1).astype('int')\n",
    "\n",
    "# On génère un vecteur des 'ages_t2' de taille N avec des valeurs entières générées par la fonction 'genere_nombre'\n",
    "ages_t2 = genere_nombre(30, 15, 18, 99,N).round(0).astype('int')\n",
    "\n",
    "# On génère un vecteur des 'weights_t2' de taille N avec des valeurs générées par la fonction 'genere_nombre',\n",
    "# arrondies à 2 décimales\n",
    "weights_t2 = genere_nombre(70, 10, 50, 99,N).round(2)\n",
    "\n",
    "# On génère un vecteur des 'shoulder_circumference_t2' de taille N avec des valeurs uniformément réparties \n",
    "# entre 30 et 60, arrondies à 2 décimales\n",
    "shoulder_circumference_t2 = np.random.uniform(30, 60, size=N).round(2).reshape(N,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94ba5a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassandra_dict['table2'] =  [x.tolist() for x in (id_pref,id_company_2,ages_t2,weights_t2,shoulder_circumference_t2)]\n",
    "cassandra_dict['table2'] = [[x[i][0]for x in cassandra_dict['table2']] for i in range(len(cassandra_dict['table2'][0])) ]\n",
    "len(cassandra_dict['table2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e480ce5",
   "metadata": {},
   "source": [
    "Je m'assure que les données sont correctes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a4aa37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 100001, 25, 78.29, 48.96],\n",
       " [1, 100002, 31, 73.82, 33.47],\n",
       " [2, 100003, 19, 69.19, 55.95],\n",
       " [2, 100004, 32, 65.65, 54.85],\n",
       " [1, 100005, 46, 67.75, 58.91],\n",
       " [2, 100006, 45, 61.68, 43.41],\n",
       " [2, 100007, 21, 68.69, 35.75],\n",
       " [0, 100008, 46, 67.74, 51.28],\n",
       " [2, 100009, 47, 68.65, 47.24],\n",
       " [1, 100010, 25, 78.8, 45.13]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassandra_dict['table2'][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f3fe1f0",
   "metadata": {},
   "source": [
    "#### Données de la table3\n",
    "  Les \"id_pref\" de la table3 sont créés avec une attribution de 0 au 40% les plus jeunes, 1 au 30% suivants et 2 au 30% restants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7b830dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit une variable 'N' égale à 100 000\n",
    "N = 100_000\n",
    "\n",
    "# On calcule le nombre d'individus pour chaque groupe\n",
    "groupe_jeune = int(0.4 * N)\n",
    "autre_goupe = int(0.3 * N)\n",
    "\n",
    "# On génère un vecteur des 'id_pref' en créant des tableaux de 0, 1 et 2 avec les tailles calculées précédemment, \n",
    "# puis on les concatène et on redimensionne en une matrice N x 1\n",
    "id_pref = np.hstack((np.full(groupe_jeune, 0), np.full(autre_goupe, 1), np.full(autre_goupe, 2))).reshape(N,1).astype('int')\n",
    "\n",
    "# On crée un vecteur des 'id_company_3' avec des valeurs allant de N+1 à 2*N inclus\n",
    "id_company_3 = np.array(range(N+1,2*N+1)).reshape(N,1).astype('int')\n",
    "\n",
    "# On génère un vecteur des 'ages_t3' de taille N avec des valeurs entières générées par la fonction 'genere_nombre',\n",
    "# puis on les trie par ordre croissant\n",
    "ages_t3 = np.array(sorted(genere_nombre(30,10,18,99,N).round(0).astype('int')))\n",
    "\n",
    "# On génère un vecteur des 'weights_t3' en ajoutant 50 à la racine carrée des âges\n",
    "weights_t3 = 50 + np.sqrt(ages_t3).round(2)\n",
    "\n",
    "# On génère un vecteur des 'shoulder_circumference_t3' en ajoutant 10 au double du logarithme naturel des âges\n",
    "shoulder_circumference_t3 = (10 + 2 * np.log(ages_t3)).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9eea24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassandra_dict['table3'] = [x.tolist() for x in (id_pref,id_company_3,ages_t3,weights_t3,shoulder_circumference_t3)]\n",
    "cassandra_dict['table3'] = [[x[i][0]for x in cassandra_dict['table3']] for i in range(len(cassandra_dict['table3'][0])) ]\n",
    "len(cassandra_dict['table3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fca3e1",
   "metadata": {},
   "source": [
    "Je m'assure que les données sont correctes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b10afc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 100001, 18, 54.24, 15.78],\n",
       " [0, 100002, 18, 54.24, 15.78],\n",
       " [0, 100003, 18, 54.24, 15.78],\n",
       " [0, 100004, 18, 54.24, 15.78],\n",
       " [0, 100005, 18, 54.24, 15.78],\n",
       " [0, 100006, 18, 54.24, 15.78],\n",
       " [0, 100007, 18, 54.24, 15.78],\n",
       " [0, 100008, 18, 54.24, 15.78],\n",
       " [0, 100009, 18, 54.24, 15.78],\n",
       " [0, 100010, 18, 54.24, 15.78]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassandra_dict['table3'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c91fdf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100000, 100000, 100000]\n"
     ]
    }
   ],
   "source": [
    "# On s'assure que toutes les données ont été générées en vérifiant la taille des tables dans le dictionnaire.\n",
    "print([len(l) for l in cassandra_dict.values()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbb5e6db",
   "metadata": {},
   "source": [
    "Aprés connexion au cluster, je créé le keyspace. Une fois connecté à ce dernier, je créé les tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6509fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapté pour cassandra \n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "# On se connecte au cluster Cassandra\n",
    "cluster_addresses = ['172.31.160.1']\n",
    "auth_provider = PlainTextAuthProvider(username='cassandra', password='cassandra')\n",
    "cluster=Cluster(cluster_addresses, auth_provider=auth_provider,  connect_timeout=10)\n",
    "session = cluster.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53212201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fb62c4c9d50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Un temps de réponse de cassandra parfois long m'oblige à définir un timeout de 30 secondes\n",
    "timeout = 30\n",
    "# Création d'un keyspace avec une seule réplication \n",
    "session.execute(\"CREATE KEYSPACE IF NOT EXISTS tp_cassandra WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}\", timeout=timeout)\n",
    "\n",
    "# Connection au keyspace créé\n",
    "session.set_keyspace('tp_cassandra')\n",
    "\n",
    "# Création des tables\n",
    "session.execute(\"CREATE TABLE IF NOT EXISTS table1 (id_pref int, id_company int, age int, weight float, shoulder_circumference float, PRIMARY KEY (id_company))\", timeout=timeout)\n",
    "session.execute(\"CREATE TABLE IF NOT EXISTS table2 (id_pref int, id_company int, age int, weight float, shoulder_circumference float, PRIMARY KEY (id_company))\", timeout=timeout)\n",
    "session.execute(\"CREATE TABLE IF NOT EXISTS table3 (id_pref int, id_company int, age int, weight float, shoulder_circumference float, PRIMARY KEY (id_company))\", timeout=timeout)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d842ef1",
   "metadata": {},
   "source": [
    "Afin de charger rapidement les données dans cassandra, j'ai créé une fonction qui le fait en batch. Je suis limité à une taille de batch de 100 sur ma machine mais cela est très rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5e6f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.query import BatchStatement\n",
    "from tqdm import tqdm\n",
    "\n",
    "def execute_batch(rows, table_name, session, batch_size=100):\n",
    "    for i in tqdm(range(0, len(rows), batch_size), desc=f\"Insertion de données dans la {table_name}\"):\n",
    "        batch = BatchStatement()\n",
    "        for row in [rows[i:(i + batch_size)][0]]:\n",
    "            query = f\"INSERT INTO {table_name} (id_pref, id_company, age, weight, shoulder_circumference) VALUES (%s, %s, %s, %s, %s)\"\n",
    "            batch.add(query, row)\n",
    "        session.execute(batch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6943735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insertion de données dans la table1: 100%|██████████| 1000/1000 [00:01<00:00, 514.49it/s]\n",
      "Insertion de données dans la table2: 100%|██████████| 1000/1000 [00:01<00:00, 542.19it/s]\n",
      "Insertion de données dans la table3: 100%|██████████| 1000/1000 [00:01<00:00, 534.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ajout des lignes à chaque table avec la fonction créée\n",
    "execute_batch(cassandra_dict[\"table1\"], \"table1\", session)\n",
    "execute_batch(cassandra_dict[\"table2\"], \"table2\", session)\n",
    "execute_batch(cassandra_dict[\"table3\"], \"table3\", session)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1d52c9f",
   "metadata": {},
   "source": [
    "Pour s'assuré que les données sont bien chargées dans cassandra on contrôle la taille des tables est les première lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34fef9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40822/2839940524.py:1: DeprecationWarning: ResultSet indexing support will be removed in 4.0. Consider using ResultSet.one() to get a single row.\n",
      "  print([j[0] for j in [session.execute(f\"SELECT count(*) FROM tp_cassandra.table{i}\") for i in range(1,4)]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(count=1000), Row(count=1000), Row(count=1000)]\n",
      "{'Table1': [Row(id_company=71801, age=25, id_pref=2, shoulder_circumference=37.58000183105469, weight=73.30000305175781), Row(id_company=5801, age=42, id_pref=1, shoulder_circumference=57.150001525878906, weight=91.6500015258789), Row(id_company=54001, age=27, id_pref=0, shoulder_circumference=39.41999816894531, weight=56.15999984741211), Row(id_company=4701, age=32, id_pref=0, shoulder_circumference=53.33000183105469, weight=68.95999908447266), Row(id_company=58201, age=19, id_pref=0, shoulder_circumference=51.150001525878906, weight=67.54000091552734)]}\n",
      "{'Table2': [Row(id_company=140501, age=38, id_pref=0, shoulder_circumference=57.900001525878906, weight=61.83000183105469), Row(id_company=111501, age=37, id_pref=1, shoulder_circumference=42.9900016784668, weight=57.349998474121094), Row(id_company=196901, age=36, id_pref=0, shoulder_circumference=36.349998474121094, weight=75.20999908447266), Row(id_company=196601, age=32, id_pref=1, shoulder_circumference=48.45000076293945, weight=61.47999954223633), Row(id_company=178201, age=41, id_pref=0, shoulder_circumference=43.2599983215332, weight=85.6500015258789)]}\n",
      "{'Table3': [Row(id_company=140501, age=29, id_pref=1, shoulder_circumference=16.729999542236328, weight=55.38999938964844), Row(id_company=111501, age=22, id_pref=0, shoulder_circumference=16.18000030517578, weight=54.689998626708984), Row(id_company=196901, age=49, id_pref=2, shoulder_circumference=17.780000686645508, weight=57.0), Row(id_company=196601, age=49, id_pref=2, shoulder_circumference=17.780000686645508, weight=57.0), Row(id_company=178201, age=39, id_pref=2, shoulder_circumference=17.329999923706055, weight=56.2400016784668)]}\n"
     ]
    }
   ],
   "source": [
    "print([j[0] for j in [session.execute(f\"SELECT count(*) FROM tp_cassandra.table{i}\") for i in range(1,4)]])\n",
    "for i in range(1, 4):\n",
    "    print({f\"Table{i}\": session.execute(f\"SELECT * FROM tp_cassandra.table{i} limit 5\")[:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df5520fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# On ferme  la connexion au cluster\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-return",
   "metadata": {},
   "source": [
    "On va modifie le K-means presente plus pour qu'il partitionne les trois tables créées. \n",
    "On considère que les données avec ID_pref=0 sont sur le serveur 0, ID_pref=1 sur le serveur 1 et ID_pref=2 sur le serveur 2.\n",
    "L'algorithme ne peut pas agreger les donnees de differents serveurs. \n",
    "Il faut ecrire une fonction qui recois les moyennes des centroides durant une itération\n",
    "Calcul de nouvelles moyennes par rapport aux données dans un serveur\n",
    "\n",
    "A partir de ces moyennes par serveur, on va generer une moyenne globale.\n",
    "\n",
    "NB chaque serveur contribue a la moyenne globale en fonction des nombre d'elements dans ce dernier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f054d5a4",
   "metadata": {},
   "source": [
    "## Kmeans distribué"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87f70ea9",
   "metadata": {},
   "source": [
    "Dans un premier temps je créé un nouvel keyspace qui va contenir les nouvelles tables.\n",
    "Ces tables seront partitionnées suivant l'id_pref (clé de particitionnement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cef091fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "# Définition du délai d'attente de connexion en secondes\n",
    "connect_timeout_in_seconds = 10\n",
    "# Utilisation de l'adresse IP du cluster et les ports spécifiés pour chaque instance Docker Cassandra\n",
    "cluster_addresses = ['172.31.160.1']\n",
    "\n",
    "# Connexion au cluster avec l'authentification \n",
    "auth_provider = PlainTextAuthProvider(username='cassandra', password='cassandra')\n",
    "cluster = Cluster(cluster_addresses, auth_provider=auth_provider, connect_timeout=connect_timeout_in_seconds)\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba06738c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fb641a098d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création du keyspace avec la stratégie de réplication SimpleStrategy\n",
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS exe_3\n",
    "    WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}\n",
    "\"\"\", timeout=20)\n",
    "\n",
    "# On utilise le keyspace créé\n",
    "session.set_keyspace('exe_3')\n",
    "\n",
    "# On Créé les tables avec id_pref comme clé de partition\n",
    "table_creation_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {} (\n",
    "        id_pref int,\n",
    "        id_company int,\n",
    "        age int,\n",
    "        weight float,\n",
    "        shoulder_circumference float,\n",
    "        PRIMARY KEY (id_pref, id_company)\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "# Création des trois nouvelles tables \n",
    "session.execute(table_creation_query.format(\"data1\"), timeout=60)\n",
    "session.execute(table_creation_query.format(\"data2\"), timeout=60)\n",
    "session.execute(table_creation_query.format(\"data3\"), timeout=60)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9f545aa",
   "metadata": {},
   "source": [
    "Je créé une nouvelle fonction de chargement de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bccb8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def insert_data(table_cas, table_dict):    \n",
    "    for row in tqdm(cassandra_dict[table_dict], desc=f\"Insertion de données dans la {table_cas}\"):\n",
    "        query = f\"INSERT INTO {table_cas} (id_pref, id_company, age, weight, shoulder_circumference) VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, row, timeout=120)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc59bfb9",
   "metadata": {},
   "source": [
    "Ensuite, on charge les données des dictionnaires `cassandra_dict` dans ces tables.\n",
    "Les données sont réparties sur les 3 serveurs suivant leur id_pref pour tester l'algorithme de Kmeans distribué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84cc82b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insertion de données dans la data1: 100%|██████████| 100000/100000 [03:35<00:00, 464.80it/s]\n",
      "Insertion de données dans la data2: 100%|██████████| 100000/100000 [03:40<00:00, 453.03it/s]\n",
      "Insertion de données dans la data3: 100%|██████████| 100000/100000 [03:49<00:00, 435.12it/s]\n"
     ]
    }
   ],
   "source": [
    "insert_data('data1','table1')\n",
    "insert_data('data2','table2')\n",
    "insert_data('data3','table3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3434f9d",
   "metadata": {},
   "source": [
    "Pour savoir à quoi m'attendre comme moyenne globale des centroïdes je la calcule avec le kmeans fourni plus haut. \n",
    "\n",
    "Dans un premier temps je convertis les colonnes des caractéristiques en numpy array pour pouvoir les utiliser avec la fonction `kmeans_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82939ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des features en np.array\n",
    "t1 = np.array([x[2:] for x in cassandra_dict['table1']])\n",
    "t2 = np.array([x[2:] for x in cassandra_dict['table2']])\n",
    "t3 = np.array([x[2:] for x in cassandra_dict['table3']])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4504d911",
   "metadata": {},
   "source": [
    "Ensuite, je calcule la moyenne des centroïdes pour chaque table et je récurère les indices de tous les points.\n",
    "Enfin, je calcule la moyenne globale des centroïdes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfafc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les indices, qui vont servir à connaitre le nombre d'élèment dans chaque table, \n",
    "# ainsi que la moyenne des centroïde pour chaque table\n",
    "num_clusters = 7\n",
    "ind1, kmns1 = kmeans_(t1, num_clusters)\n",
    "ind2, kmns2 = kmeans_(t2, num_clusters)\n",
    "ind3, kmns3 = kmeans_(t3, num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85d282db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# On calcule la moyenne globale \n",
    "kmeans_moyenne_globale = (kmns1*len(ind1) + kmns2*len(ind2) + kmns3*len(ind3))/(len(ind1) + len(ind2) + len(ind3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9c96b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des centroïdes pour 7 clusters:\n",
      "6.81622184287636\n"
     ]
    }
   ],
   "source": [
    "# On affiche la moyenne des centroïdes calculée\n",
    "print(f\"Moyenne des centroïdes pour {num_clusters} clusters:\")\n",
    "print(kmeans_moyenne_globale)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29ab6130",
   "metadata": {},
   "source": [
    "Cette moyenne globale me permettra de contrôler le que mon kmeans distribué me retourne une valeur cohérente. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "927b1eb3",
   "metadata": {},
   "source": [
    "Pour l'adaption de l'algorithme de kmeans plus haut, je créé quelques fonctions utiles pour la suite.\n",
    "La fonction `get_table_names_with_columns` récupère les noms des tables contenant les colonnes spécifiées. La fonction `get_server_data` récupère les données d'un serveur selon l'identifiant du serveur, le nom du keyspace et le nom de la table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85b98a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb84e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from cassandra.query import SimpleStatement\n",
    "\n",
    "def get_table_names_with_columns(keyspace, column_names):\n",
    "    # On interroge la base de données pour obtenir les noms de tables et les noms de colonnes\n",
    "    query = f\"SELECT table_name, column_name FROM system_schema.columns WHERE keyspace_name = '{keyspace}';\"\n",
    "    statement = SimpleStatement(query, fetch_size=100)\n",
    "    rows = session.execute(statement)\n",
    "\n",
    "    # On stocke les noms de tables qui ont les colonnes spécifiées\n",
    "    tables_with_columns = {}\n",
    "    for row in rows:\n",
    "        if row.column_name in column_names:\n",
    "            if row.table_name not in tables_with_columns:\n",
    "                tables_with_columns[row.table_name] = set()\n",
    "            tables_with_columns[row.table_name].add(row.column_name)\n",
    "\n",
    "    # On conserve uniquement les noms de tables qui ont toutes les colonnes spécifiées\n",
    "    table_names = [table_name for table_name, columns in tables_with_columns.items() if columns == set(column_names)]\n",
    "\n",
    "    return table_names\n",
    "\n",
    "def get_server_data(server_id, keyspace, table_name):\n",
    "    # On interroge la base de données pour obtenir les données du serveur\n",
    "    query = f\"SELECT age, weight, shoulder_circumference FROM {keyspace}.{table_name} WHERE id_pref = {server_id}\"\n",
    "    statement = SimpleStatement(query, fetch_size=100)\n",
    "    rows = session.execute(statement)\n",
    "\n",
    "    # On convertit les résultats en une liste d'arrays numpy\n",
    "    server_data = [np.array([row.age, row.weight, row.shoulder_circumference]) for row in rows]\n",
    "\n",
    "    if len(server_data) > 0:\n",
    "        return np.vstack(server_data)\n",
    "    else:\n",
    "        return np.empty((0, 3))  # On retourne un tableau vide avec 3 colonnes (age, weight, shoulder_circumference)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16ef8ce3",
   "metadata": {},
   "source": [
    "On s'assure que les fonctions sont correctes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6c45000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62.        , 68.26999664, 35.18999863],\n",
       "       [22.        , 72.83000183, 31.81999969],\n",
       "       [48.        , 98.47000122, 33.75      ],\n",
       "       [23.        , 82.47000122, 39.36000061],\n",
       "       [31.        , 52.09999847, 36.08000183]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = {'id_pref', 'id_company', 'age', 'weight', 'shoulder_circumference'}\n",
    "table_name = get_table_names_with_columns(keyspace='exe_3', column_names=column_names)\n",
    "df = get_server_data(1, 'exe_3', table_name[0])\n",
    "df[np.random.choice(df.shape[0],5,replace=False),:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b8a5061",
   "metadata": {},
   "source": [
    "Enfin, on créé la fonction de kmeans distribué en s'appuyant sur la fonction kmeans existante.\n",
    "La fonction kmeans_ effectue l'algorithme K-means pour la mise en cluster des données. La fonction kmeans_distributed effectue le K-means de manière distribuée, en récupérant les données de plusieurs serveurs et en calculant les centroïdes finaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1dc6897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def kmeans_(feats, num_clus):\n",
    "    # On vérifie si les données sont vides\n",
    "    if feats.shape[0] == 0:\n",
    "        return np.array([]), np.nan  # On retourne un tableau vide et une valeur NaN pour les distances moyennes\n",
    "        \n",
    "    max_iter = 10000\n",
    "    max_delta = 0.001\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "    iter_ = 0\n",
    "    delta_ = 0\n",
    "    centroides = feats[np.random.choice(feats.shape[0], num_clus, replace=False), :]\n",
    "    \n",
    "    while(iter_ < max_iter):\n",
    "        iter_ += 1\n",
    "        if not np.any(np.isnan(centroides)):\n",
    "            nbrs.fit(centroides)            \n",
    "            distances, indices = nbrs.kneighbors(feats)\n",
    "            centroides_prev = copy.deepcopy(centroides)\n",
    "        \n",
    "            for i in range(centroides.shape[0]):\n",
    "                centroides[i, :] = feats[np.where(indices[:, 0] == i)[0], :].mean(axis=0)\n",
    "            # On vérifie la convergence en comparant la différence entre les anciens et les nouveaux centroïdes.\n",
    "            delta_ = np.linalg.norm(centroides - centroides_prev)\n",
    "            if delta_ < max_delta:\n",
    "                break\n",
    "    return indices[:, 0], distances.mean()\n",
    "\n",
    "def kmeans_distributed(keyspace, column_names, num_clusters, num_servers):\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    table_names = get_table_names_with_columns(keyspace=keyspace, column_names=column_names)\n",
    "    server_id = range(num_servers)\n",
    "    centroids = []\n",
    "    poids = []\n",
    "    for i in tqdm(server_id, desc=f\"recupération données serveur\"):\n",
    "        for table in table_names:\n",
    "            data = get_server_data(i, keyspace, table)\n",
    "            \n",
    "            # On calcule la moyenne de chaque colonne en excluant les valeurs NaN\n",
    "            column_means = np.nanmean(data, axis=0)\n",
    "            \n",
    "            # On trouve les indices des valeurs NaN\n",
    "            inds = np.where(np.isnan(data))\n",
    "            \n",
    "            # On remplit les valeurs NaN avec les moyennes correspondantes de la colonne\n",
    "            data[inds] = np.take(column_means, inds[1])\n",
    "            \n",
    "            if data.size > 0:\n",
    "                indices, distances_moyenne = kmeans_(data, num_clusters)\n",
    "                if len(indices) > 0 and not np.isnan(distances_moyenne):\n",
    "                    centroids.append(distances_moyenne)\n",
    "                    poids.append(len(indices))\n",
    "\n",
    "    moyenne_golobale = np.array(centroids).dot(np.array(poids)) / np.array(poids).sum()\n",
    "    \n",
    "    return moyenne_golobale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "222746ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "recupération données serveur: 100%|██████████| 3/3 [00:14<00:00,  4.72s/it]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# On récupére les noms des tables qui ont les colonnes spécifiées\n",
    "\n",
    "column_names = {'id_pref', 'id_company', 'age', 'weight', 'shoulder_circumference'}\n",
    "\n",
    "# On exécute le K-means distribué sur les données de tous les serveurs\n",
    "num_clusters = 7\n",
    "kmeans_distribute_moyenne_globale = kmeans_distributed(keyspace='exe_3', column_names=column_names, num_clusters=num_clusters, num_servers=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd8f0dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans distribué : Moyenne des centroïdes pour 7 clusters:\n",
      "7.25167867405137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  On affiche la moyenne des centroïdes calculée\n",
    "print(f\"Kmeans distribué : Moyenne des centroïdes pour {num_clusters} clusters:\")\n",
    "print(kmeans_distribute_moyenne_globale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a07af4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'écart entre les deux kmeans est de 6.39 pourcent.\n"
     ]
    }
   ],
   "source": [
    "difference_entre_deux_kmeans = kmeans_distribute_moyenne_globale/kmeans_moyenne_globale - 1\n",
    "print(f\"L'écart entre les deux kmeans est de {round(difference_entre_deux_kmeans, 4)*100} pourcent.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c6acf2f",
   "metadata": {},
   "source": [
    "On constate que les resultats des deux algorithmes (kmeans et kmeans distribués) sont très proches pour un nombre de clusters identiques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbdenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb02c79aec7f693a07e469ee2420513af08c9d25fa18f571f9e9edc2b2071833"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
