{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ";'';'';'';'';'';'';'';'';'';'';'';'';'';''\n",
    "Num_Acc:Num_Acc,\n",
    " Adresse_postale:adr,\n",
    " Commune:com,\n",
    " Conditions_atmosphériques:atm,\n",
    " Département:dep,\n",
    " Intersection:int,\n",
    " Jour:jour,\n",
    " Localisation:agg,\n",
    " Long:long,\n",
    " Lumière:lum,\n",
    " an\t:an,\n",
    " hrmn:hrmn,\n",
    " lat:lat,\n",
    " mois:mois,\n",
    " Type_de_collision:col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Adresse_postale', 'Commune', 'Conditions_atmosphériques', 'Département', 'Intersection', 'Jour', 'Localisation', 'Long', 'Lumière', 'an'\t, 'hrmn', 'lat', 'mois', 'Type_de_collision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALL apoc.load.csv('file:///caracteristiques.csv',\n",
    "    {header:true, ignore:{'Num_Acc','Adresse_postale', 'Commune', 'Conditions_atmosphériques', 'Département', 'Intersection', 'Jour', 'Localisation', 'Long', 'Lumière', 'an'\t, 'hrmn', 'lat', 'mois', 'Type_de_collision'}},\n",
    "    mapping:{'Num_Acc:Num_Acc,Adresse_postale:adr,Commune:com,Conditions_atmosphériques:atm,Département:dep,Intersection:int,Jour:jour,Localisation:agg,Long:long,Lumière:lum,an:an,hrmn:hrmn,lat:lat,mois:mois,Type_de_collision:col'}) yield  map \n",
    "RETURN *;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Num_Acc\",\"Jour\",\"mois\",\"an\",\"hrmn\",\"lum\",\"dep\",\"com\",\"agg\",\"int\",\"atm\",\"col\",\"adr\",\"lat\",\"long\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Num_Accne\",\"Jour\",\"Mois\",\"An\",\"Heure\",\"Lumière\",\"Département\",\"Commune\",\"Localisation\",\"Intersection\",\"Conditions_atmosphériques\",\"Type_de_collision\",\"Adresse_postale\",\"Latitude\",\"Longitude\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD CSV WITH HEADERS FROM 'file:///caracteristiques.csv' AS line\n",
    "WITH line \n",
    "WHERE line.Num_Acc IS NOT NULL\n",
    "CREATE (ac:Accident {Num_Acc: line.Num_Acc}) \n",
    " RETURN count(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD CSV WITH HEADERS FROM 'file:///caracteristiques.csv' AS line \n",
    "WITH line WHERE line.Num_Acc IS NOT NULL\n",
    "CREATE (ac:Accident {\n",
    "Num_Acc: line.Num_Acc,\n",
    "Jour: line.Jour,\n",
    "Mois: line.Mois,\n",
    "An: line.An,\n",
    "Heure: line.Heure,\n",
    "Lumière: line.Lumière,\n",
    "Département: line.Département,\n",
    "Commune: line.Commune,\n",
    "Localisation: line.Localisation,\n",
    "Intersection: line.Intersection,\n",
    "Conditions_atmosphériques: line.Conditions_atmosphériques,\n",
    "Type_de_collision: line.Type_de_collision,\n",
    "Adresse_postale: line.Adresse_postale,\n",
    "Latitude: line.Latitude,\n",
    "Longitude: line.Longitude\n",
    " })\n",
    " \n",
    " RETURN count(*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD CSV WITH HEADERS FROM 'file:///caracteristiques.csv' AS line FIELDTERMINATOR ','\n",
    "WITH line \n",
    "WHERE line.Num_Acc IS NOT NULL\n",
    "MERGE (ac:Accident {Num_Acc: line.Num_Acc,\n",
    " Adresse_postale: line.adr,\n",
    " Commune: line.com,\n",
    " Conditions_atmosphériques: line.atm,\n",
    " Département: line.dep,\n",
    " Intersection: line.int,\n",
    " Jour: line.jour,\n",
    " Localisation: line.agg,\n",
    " Long: line.long,\n",
    " Lumière: line.lum,\n",
    " an: line.an,\n",
    " hrmn: line.hrmn,\n",
    " lat: line.lat,\n",
    " mois: line.mois,\n",
    " Type_de_collision: line.col})\n",
    " \n",
    " RETURN count(*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALL apoc.load.csv('file:///caracteristiques.csv',{FIELDTERMINATOR :',',\n",
    "    headers: true})\n",
    "    yield map as line\n",
    "WITH line \n",
    "WHERE line.Num_Acc IS NOT NULL\n",
    "MERGE (ac:Accident {Num_Acc: line.Num_Acc,\n",
    " Adresse_postale\t: line.adr,\n",
    " Commune\t: line.com,\n",
    " Conditions_atmosphériques\t: line.atm,\n",
    " Département\t: line.dep,\n",
    " Intersection\t: line.int,\n",
    " Jour: line.jour,\n",
    " Localisation\t: line.agg,\n",
    " Long\t: line.long,\n",
    " Lumière\t: line.lum,\n",
    " an\t: line.an,\n",
    " hrmn: line.hrmn,\n",
    " lat\t: line.lat,\n",
    " mois: line.mois,\n",
    " Type_de_collision: line.col})\n",
    " ON CREATE SET ac.Num_Acc = toInteger(line.Num_Acc)\n",
    " RETURN count(*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create keyspace ai with replication={'class':'SimpleStrategy' 'replication_factor':1} AND durable_writes=true;\n",
    "\n",
    "Create table employee_by_car_make(car_make text id int car_model text Primary key(car_makeid));\n",
    "Create table employee_by_car_make_sorted(car_make text age int id int car_model text Primary key (car_makeageid));\n",
    "create TABLE ai.employee_by_car_make_and_model (car_make text car_model text id int name text PRIMARY KEY (car_make car_model id));\n",
    "\n",
    "insert into \n",
    "\n",
    "create TABLE employee_by_id (id int name text position text  PRIMARY KEY (id));\n",
    "\n",
    "insert into employee_by_id (id, name, position) values (1,'omar','lecturer');\n",
    "\n",
    "insert into employee_by_id (id, name, position) values (1,'omar','student');\n",
    "\n",
    "insert into employee_by_id (id, name, position) values (2,'omar','student');\n",
    "select * from employee_by_id where id=1;\n",
    "select * from employee_by_car_make where car_make='BMW' order by id;\n",
    "\n",
    "\n",
    "\n",
    "select car_make writetime(car_model) from employee_by_car_make;\n",
    "update employee_by_car_make set car_model='TRUCK' where car_make='BMW' AND id=1;\n",
    "update employee_by_car_make using TTL 60 set car_model='citadine' where car_make='BMW' and id=1;\n",
    "\n",
    "\n",
    "ALTER TABLE employee_by_id ADD phone SET<text>;\n",
    "\n",
    "UPDATE employee_by_id SET phone={'341''345'} WHERE id=1;\n",
    "\n",
    "UPDATE employee_by_id SET phone=phone+{'555'} WHERE id=1;\n",
    "\n",
    "SELECT * FROM employee_by_id WHERE name='john' ALLOW FILTERING;\n",
    "\n",
    "CREATE INDEX ON employee_by_id (name);\n",
    "\n",
    "\n",
    "\n",
    "Create table employee_by_uuid(id uuid primary key, first_name text, last_name text );\n",
    "Insert into employee_by_uuid(id,first_name,last_name) values (uuid(),'simon','dupont');\n",
    "Create table employee_by_timeuuid(id timeuuid primary key,first_name text,last_name VARCHAR);\n",
    "Insert into employee_by_timeuuid(id,first_name,last_name) values (now(),'simon', 'dupont');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE table table_voiture_proprietaire(marque text, type_voiture text, annee_achat int, id_proprietaire int, type_util text, nom text, prenom text, PRIMARY KEY (annee_achat, id_proprietaire)); \n",
    "\n",
    "https://drive.google.com/file/d/FILE_ID/view?usp=sharing\n",
    "wget https://drive.google.com/uc?id=FILE_ID -O file.csv\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1CSg_vpZv5dvvN_RFN-x6VQpPP3KQX-0Zuay2bXYJVrI/edit?usp=sharing\n",
    "wget https://docs.google.com/uc?id=1CSg_vpZv5dvvN_RFN-x6VQpPP3KQX-0Zuay2bXYJVrI -O export_cass.csv\n",
    "https://docs.google.com/spreadsheets/d/1CSg_vpZv5dvvN_RFN-x6VQpPP3KQX-0Zuay2bXYJVrI/edit?usp=share_link\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1CSg_vpZv5dvvN_RFN-x6VQpPP3KQX-0Zuay2bXYJVrI/edit?usp=sharing\n",
    "https://docs.google.com/spreadsheets/d/1CSg_vpZv5dvvN_RFN-x6VQpPP3KQX-0Zuay2bXYJVrI/edit?usp=share_link\n",
    "\n",
    "wget https://drive.google.com/uc?id=1mm_rWOjH-KUhG7GwwMJHho_Al66RDsI0 -O export_cass.csv\n",
    "\n",
    "wget https://drive.google.com/uc?id=1NoCgAIIySpYK0GjREiwql8iYEzfFIwFB -O populate.txt\n",
    "\n",
    "wget https://drive.google.com/uc?id=1-hSYlhpLcQT5ThJ3RgjpIAsZK40pPaq4 -O kmeans-decentralise.ipynb\n",
    "wget https://drive.google.com/uc?id=1GBFWQW0yQoFsJAOk_Bj95Rn2t-lyGOSt -O kmeans-decentralise.py\n",
    "https://drive.google.com/file/d/1GBFWQW0yQoFsJAOk_Bj95Rn2t-lyGOSt/view?usp=sharing\n",
    "\n",
    "COPY table_voiture_proprietaire (marque, type_voiture, annee_achat, id_proprietaire, type_util, nom, prenom) FROM 'export_cass.csv' WITH DELIMITER = ',';\n",
    "'BMW', 'TRUCK',2019,1,'cs','omar','jaafor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create 'students', 'account', 'address'\n",
    "create 'clicks', 'clickinfo', 'iteminfo'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le filtre FirstKeyOnlyFilter() ne retourne que la première clé de chaque ligne de la table, et ignore les colonnes et les valeurs de cette ligne. \n",
    "Cela peut être utile lorsqu'il est nécessaire de parcourir rapidement une grande table en ne récupérant que le minimum de données nécessaire.\n",
    "\n",
    "Le filtre KeyOnlyFilter() est similaire au filtre FirstKeyOnlyFilter(), mais il retourne la clé de chaque ligne de la table au lieu de seulement la première clé.\n",
    "\n",
    "Le filtre {COLUMNS=>\"account:name\",limit:3,FILTER=>\"ValueFilter(=,'binary:Bob')\"} effectuera un balayage de la table en ne récupérant que la colonne name de la famille de colonnes account, \n",
    "en ne retournant que les 3 premières lignes de la table qui ont une valeur de Bob dans la colonne name.\n",
    "\n",
    "Le filtre PrefixFilter retourne les lignes qui ont une clé qui commence par le préfixe spécifié. Dans ce cas, le filtre PrefixFilter('s') retournera les lignes qui ont une clé qui commence par la lettre 's'. Utile lorsqu'il est nécessaire de récupérer rapidement un groupe de lignes qui ont des clés qui partagent un préfixe commun.\n",
    "\n",
    "Le filtre PrefixFilter('s') AND ColumnPrefixFilter('na') combinera deux filtres en utilisant l'opérateur logique AND. Le premier filtre, PrefixFilter('s'), \n",
    "retournera les lignes qui ont une clé qui commence par le préfixe 's'. Le deuxième filtre, ColumnPrefixFilter('na'), retournera les colonnes qui ont un nom de colonne qui commence par le préfixe 'na'. Les lignes retournées par la numérisation auront une clé qui commence par 's' et incluront uniquement les colonnes qui ont un nom de colonne qui commence par 'na'.\n",
    "\n",
    "Le filtre PrefixFilter('s') AND MultipleColumnPrefixFilter('s','name') combinera deux filtres en utilisant l'opérateur logique AND. Le premier filtre, PrefixFilter('s'), \n",
    "retournera les lignes qui ont une clé qui commence par le préfixe 's'. Le deuxième filtre, MultipleColumnPrefixFilter('s','name'), retournera les colonnes qui ont un nom de colonne qui commence par l'un des préfixes spécifiés, dans ce cas 's' ou 'name'. Les lignes retournées par la numérisation auront une clé qui commence par 's' et incluront uniquement les colonnes qui ont un nom de colonne qui commence par 's' ou 'name'.\n",
    "\n",
    "Le filtre ColumnCountGetFilter retourne un nombre maximum de colonnes spécifiées pour chaque ligne. Dans ce cas, le filtre ColumnCountGetFilter(2) retournera au maximum 2 colonnes pour chaque ligne de la table. \n",
    "\n",
    "Le filtre PageFilter retourne un nombre spécifié de lignes sous forme de pages. Dans ce cas, le filtre PageFilter(1) retournera une page de lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert into ai.employee_by_car_make_and_model (car_make, car_model, id, name) values ('BMW','TRUCK',1,'bbmw');\n",
    "insert into ai.employee_by_car_make_and_model (car_make, car_model, id, name) values ('Audi','mini',2,'baudi');\n",
    "insert into ai.employee_by_car_make_and_model (car_make, car_model, id, name) values ('Mercedes','berline',3,'bmercedes');\n",
    "\n",
    "\n",
    "Create table purchases_by_customer_id(id uuid primary key, purchases counter);\n",
    "Update purchases_by_customer_id set purchases=purchases+1 where id=uuid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table must exist\n",
    "Primary keys exist and unique in csv\n",
    "Columns in table but not in csv set to null\n",
    "Create table test_csv(….)\n",
    "Copy test_csv (columns) from ‘file path’ with delimiter=’,’\n",
    "and header==True\n",
    "Copy test_csv to ‘destination’ with delimiter==’,’\n",
    "Copy test_csv(columns) to ‘destination’ with delimiter=’,’\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((  loader.'data', loader.'indices', loader.'indptr',)\n",
    "                         shape = loader.'shape',)\n",
    "def save_sparse_csr(filenamearray):\n",
    "    np.savez(filenamedata = array.data indices=array.indices\n",
    "             indptr =array.indptr shape=array.shape )\n",
    "\n",
    "def to_sparse(graph weight_attr=None):\n",
    "    edges = graph.get_edgelist()\n",
    "    if weight_attr is None:\n",
    "        weights = .1, * len(edges)\n",
    "    else:\n",
    "        weights = graph.es.weight_attr,\n",
    "    if not graph.is_directed():\n",
    "        edges.extend(.(v u) for u v in edges,)\n",
    "        weights.extend(weights)\n",
    "    return sparse.csr_matrix((weights zip(*edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('tweets.csv'encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>replyToSN</th>\n",
       "      <th>created</th>\n",
       "      <th>truncated</th>\n",
       "      <th>replyToSID</th>\n",
       "      <th>id</th>\n",
       "      <th>replyToUID</th>\n",
       "      <th>statusSource</th>\n",
       "      <th>screenName</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @mrvelstan: literally nobody:\\r\\nme:\\r\\n\\r\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-23 10:43:30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1120639328034676737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>DavidAc96</td>\n",
       "      <td>637</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @agntecarter: i’m emotional, sorry!!\\r\\n\\r\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-23 10:43:30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1120639325199196160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NRmalaa</td>\n",
       "      <td>302</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>saving these bingo cards for tomorrow \\r\\n©\\r\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-23 10:43:30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1120639324683292674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>jijitsuu</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @HelloBoon: Man these #AvengersEndgame ads ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-23 10:43:29</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1120639323328540672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>SahapunB</td>\n",
       "      <td>23781</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>RT @Marvel: We salute you, @ChrisEvans! #Capta...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-23 10:43:29</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1120639321571074048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>stella22_97</td>\n",
       "      <td>13067</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  favorited  \\\n",
       "0           1  RT @mrvelstan: literally nobody:\\r\\nme:\\r\\n\\r\\...      False   \n",
       "1           2  RT @agntecarter: i’m emotional, sorry!!\\r\\n\\r\\...      False   \n",
       "2           3  saving these bingo cards for tomorrow \\r\\n©\\r\\...      False   \n",
       "3           4  RT @HelloBoon: Man these #AvengersEndgame ads ...      False   \n",
       "4           5  RT @Marvel: We salute you, @ChrisEvans! #Capta...      False   \n",
       "\n",
       "   favoriteCount replyToSN              created  truncated  replyToSID  \\\n",
       "0              0       NaN  2019-04-23 10:43:30      False         NaN   \n",
       "1              0       NaN  2019-04-23 10:43:30      False         NaN   \n",
       "2              0       NaN  2019-04-23 10:43:30      False         NaN   \n",
       "3              0       NaN  2019-04-23 10:43:29      False         NaN   \n",
       "4              0       NaN  2019-04-23 10:43:29      False         NaN   \n",
       "\n",
       "                    id  replyToUID  \\\n",
       "0  1120639328034676737         NaN   \n",
       "1  1120639325199196160         NaN   \n",
       "2  1120639324683292674         NaN   \n",
       "3  1120639323328540672         NaN   \n",
       "4  1120639321571074048         NaN   \n",
       "\n",
       "                                        statusSource   screenName  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...    DavidAc96   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...      NRmalaa   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...     jijitsuu   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...     SahapunB   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...  stella22_97   \n",
       "\n",
       "   retweetCount  isRetweet  retweeted  longitude  latitude  \n",
       "0           637       True      False        NaN       NaN  \n",
       "1           302       True      False        NaN       NaN  \n",
       "2             0      False      False        NaN       NaN  \n",
       "3         23781       True      False        NaN       NaN  \n",
       "4         13067       True      False        NaN       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_=np.empty(.03,)\n",
    "word_dic={}\n",
    "i=0\n",
    "j=0\n",
    "for r in df.'text',:\n",
    "    toks=r.split()\n",
    "    for word in toks:\n",
    "        if word not in word_dic:\n",
    "            word_dic.word, = j\n",
    "            j+=1\n",
    "        try:\n",
    "            input_.i0,=i\n",
    "            input_.i1,=word_dic.word,\n",
    "            input_.i1,=1\n",
    "        except:\n",
    "            input_=np.concatenate((input_np.empty(.10003,)))\n",
    "            input_.i0,=i\n",
    "            input_.i1,=word_dic.word,\n",
    "            input_.i1,=1\n",
    "    i+=1  \n",
    "            \n",
    "input_=input_.0:i:,          \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+000, 1.00000000e+000, 4.68045793e-310],\n",
       "       [1.00000000e+000, 1.00000000e+000, 0.00000000e+000],\n",
       "       [2.00000000e+000, 1.00000000e+000, 0.00000000e+000],\n",
       "       ...,\n",
       "       [1.49970000e+004, 1.00000000e+000, 1.17528336e-319],\n",
       "       [1.49980000e+004, 1.00000000e+000, 4.94065646e-324],\n",
       "       [1.49990000e+004, 1.00000000e+000, 1.17528336e-319]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "rcd  = input_.T\n",
    "r=np.array(rdtype=int)\n",
    "c=np.array(cdtype=int)\n",
    "setg={}\n",
    "X_rep   = sparse.coo_matrix((d (r c)))\n",
    "X_rep=X_rep.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rep=X_rep.0:max(X_rep.shape)0:max(X_rep.shape),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.42899227142334\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "X_rep=X_rep.tocsr()\n",
    "x = time.time()\n",
    "\n",
    "for i in range(1000):\n",
    "    X_rep**130\n",
    "y=time.time()\n",
    "print(y - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.32164454460144\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "X_rep=X_rep.tocsc()\n",
    "x = time.time()\n",
    "for i in range(1000):\n",
    "    X_rep**130\n",
    "y=time.time()\n",
    "print(y - x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
